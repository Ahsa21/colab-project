{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahsa21/colab-project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2ba09e6",
      "metadata": {
        "id": "d2ba09e6"
      },
      "source": [
        "# Project\n",
        "# Malicious URL Classification\n",
        "# Feature-Based Detection of Benign, Defacement,Phishing, and Malware URLs\n",
        "\n",
        "Jeet Purohit, ahmad saloukha\n",
        "DVAMI22h\n",
        "jepu20@student.bth.se, ahsa22@student.bth.se"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1425dd80",
      "metadata": {
        "id": "1425dd80"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from scipy.stats import entropy\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "# evaluation measures\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "# scalers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Algorithms\n",
        "\n",
        "from sklearn.svm import LinearSVC # SVC impractial with over 10000 samples\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2e17c1a",
      "metadata": {
        "id": "f2e17c1a"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "dataset = pd.read_csv(\"malicious_URLS.csv\", sep=\",\")\n",
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe810a9",
      "metadata": {
        "id": "7fe810a9"
      },
      "source": [
        "# The class names and the total samples of each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd46ad2",
      "metadata": {
        "id": "efd46ad2"
      },
      "outputs": [],
      "source": [
        "print(f\"Total instances: {dataset.shape[0]}, Total Attributes: {dataset.shape[1]}\\n\")\n",
        "\n",
        "class0 = (dataset[\"label\"] == 0).sum()\n",
        "class1 = (dataset[\"label\"] == 1).sum()\n",
        "class2 = (dataset[\"label\"] == 2).sum()\n",
        "class3 = (dataset[\"label\"] == 3).sum()\n",
        "class0_percentage = (class0 / dataset.shape[0] * 100)\n",
        "class1_percentage = (class1 / dataset.shape[0] * 100)\n",
        "class2_percentage = (class2 / dataset.shape[0] * 100)\n",
        "class3_percentage = (class3 / dataset.shape[0] * 100)\n",
        "\n",
        "\n",
        "print(f\"Class 0 (benign URLs) samples: {class0}      | Class 0 %: {(class0_percentage):.3}%\\n\"\n",
        "      f\"Class 1 (defacement URLs) samples: {class1}   | Class 1 %: {(class1_percentage):.3}%\\n\"\n",
        "      f\"Class 2 (phishing URLs) samples: {class2}     | Class 2 %: {(class2_percentage):.3}%\\n\"\n",
        "      f\"Class 3 (malware URLs) samples: {class3}      | Class 3 %: {(class3_percentage):.3}%\\n\"\n",
        "      )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f90a2584",
      "metadata": {
        "id": "f90a2584"
      },
      "source": [
        "# Remove duplicate features\n",
        "    - in the raw dataset there was dublicate features, after checking if they had the exact same values for each sample, we have removed them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7332f5a3",
      "metadata": {
        "id": "7332f5a3"
      },
      "outputs": [],
      "source": [
        "# Remove columns with .1 suffix\n",
        "cols_to_remove = [col for col in dataset.columns if col.endswith('.1')]\n",
        "\n",
        "if cols_to_remove:\n",
        "    print(f\"Found {len(cols_to_remove)} columns with '.1' suffix:\")\n",
        "    for col in cols_to_remove:\n",
        "        print(f\"  - {col}\")\n",
        "\n",
        "    dataset = dataset.drop(columns=cols_to_remove)\n",
        "    print(f\"\\nRemoved columns with '.1' suffix\")\n",
        "    print(f\"Dataset shape after cleanup: {dataset.shape}\")\n",
        "else:\n",
        "    print(\"No columns with '.1' suffix found\")\n",
        "\n",
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13312232",
      "metadata": {
        "id": "13312232"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7f96027",
      "metadata": {
        "id": "b7f96027"
      },
      "source": [
        "# Reduced the dataset\n",
        "    - we will be using only 25% of all classes and we will still retain the overall distrubution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "228b7623",
      "metadata": {
        "id": "228b7623"
      },
      "outputs": [],
      "source": [
        "# Keep 25% of data while maintaining class distribution\n",
        "\n",
        "dataset_reduced, _ = train_test_split(dataset, train_size=0.25, stratify=dataset['label'], random_state=42)\n",
        "\n",
        "print(f\"Reduced dataset size: {len(dataset_reduced)}\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "print(dataset_reduced['label'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5033208b",
      "metadata": {
        "id": "5033208b"
      },
      "outputs": [],
      "source": [
        "print(f\"Total instances: {dataset_reduced.shape[0]}, Total Attributes: {dataset_reduced.shape[1]}\\n\")\n",
        "\n",
        "class0 = (dataset_reduced[\"label\"] == 0).sum()\n",
        "class1 = (dataset_reduced[\"label\"] == 1).sum()\n",
        "class2 = (dataset_reduced[\"label\"] == 2).sum()\n",
        "class3 = (dataset_reduced[\"label\"] == 3).sum()\n",
        "class0_percentage = (class0 / dataset_reduced.shape[0] * 100)\n",
        "class1_percentage = (class1 / dataset_reduced.shape[0] * 100)\n",
        "class2_percentage = (class2 / dataset_reduced.shape[0] * 100)\n",
        "class3_percentage = (class3 / dataset_reduced.shape[0] * 100)\n",
        "\n",
        "\n",
        "print(f\"Class 0 (benign URLs) samples: {class0}      | Class 0 %: {(class0_percentage):.3}%\\n\"\n",
        "      f\"Class 1 (defacement URLs) samples: {class1}   | Class 1 %: {(class1_percentage):.3}%\\n\"\n",
        "      f\"Class 2 (phishing URLs) samples: {class2}     | Class 2 %: {(class2_percentage):.3}%\\n\"\n",
        "      f\"Class 3 (malware URLs) samples: {class3}      | Class 3 %: {(class3_percentage):.3}%\\n\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "198d17b1",
      "metadata": {
        "id": "198d17b1"
      },
      "outputs": [],
      "source": [
        "# checking missing values\n",
        "\n",
        "nulls = dataset_reduced.isna().sum().sum()\n",
        "\n",
        "print(\"number of null\",nulls)\n",
        "print(\"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e61837b7",
      "metadata": {
        "id": "e61837b7"
      },
      "outputs": [],
      "source": [
        "# check z-core outliers\n",
        "# ÄNDRA OCH KOLLA HUR MÅNGA MALICIOUS SAMPLES VI HAR OCH DERAS AVRAGE LENGHT. TITTA PÅ FLERA OCKSÅ\n",
        "\n",
        "# Check for outliers in 'url_len' using IQR method\n",
        "col = 'url_len'\n",
        "Q1 = dataset_reduced[col].quantile(0.25)\n",
        "Q3 = dataset_reduced[col].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers_url_len = dataset_reduced[(dataset_reduced[col] < (Q1 - 1.5 * IQR)) | (dataset_reduced[col] > (Q3 + 1.5 * IQR))]\n",
        "print(f\"Outliers in '{col}': {outliers_url_len.shape[0]}\")\n",
        "\n",
        "col = 'letters'\n",
        "Q1 = dataset_reduced[col].quantile(0.25)\n",
        "Q3 = dataset_reduced[col].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers_letters = dataset_reduced[(dataset_reduced[col] < (Q1 - 1.5 * IQR)) | (dataset_reduced[col] > (Q3 + 1.5 * IQR))]\n",
        "print(f\"Outliers in '{col}': {outliers_letters.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07517e67",
      "metadata": {
        "id": "07517e67"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a67b53",
      "metadata": {
        "id": "56a67b53"
      },
      "outputs": [],
      "source": [
        "# Analyze class distribution of outliers\n",
        "print(\"=\"*60)\n",
        "print(\"OUTLIER CLASS DISTRIBUTION ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get outliers for url_len\n",
        "col = 'url_len'\n",
        "Q1 = dataset_reduced[col].quantile(0.25)\n",
        "Q3 = dataset_reduced[col].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers_url_len = dataset_reduced[(dataset_reduced[col] < (Q1 - 1.5 * IQR)) | (dataset_reduced[col] > (Q3 + 1.5 * IQR))]\n",
        "\n",
        "print(f\"\\n{col.upper()} Outliers Analysis:\")\n",
        "print(f\"Total outliers: {outliers_url_len.shape[0]}\")\n",
        "print(f\"Percentage of dataset: {(outliers_url_len.shape[0] / dataset.shape[0] * 100):.2f}%\\n\")\n",
        "\n",
        "# Class distribution in outliers\n",
        "for class_num in range(4):\n",
        "    class_count = (outliers_url_len['label'] == class_num).sum()\n",
        "    class_percentage = (class_count / outliers_url_len.shape[0] * 100)\n",
        "    class_names_dict = {0: 'Benign', 1: 'Defacement', 2: 'Phishing', 3: 'Malware'}\n",
        "\n",
        "    print(f\"Class {class_num} ({class_names_dict[class_num]}): {class_count:6d} samples | {class_percentage:5.2f}% of outliers\")\n",
        "\n",
        "# Get outliers for letters\n",
        "col = 'letters'\n",
        "Q1 = dataset_reduced[col].quantile(0.25)\n",
        "Q3 = dataset_reduced[col].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers_letters = dataset_reduced[(dataset[col] < (Q1 - 1.5 * IQR)) | (dataset_reduced[col] > (Q3 + 1.5 * IQR))]\n",
        "\n",
        "print(f\"\\n{col.upper()} Outliers Analysis:\")\n",
        "print(f\"Total outliers: {outliers_letters.shape[0]}\")\n",
        "print(f\"Percentage of dataset: {(outliers_letters.shape[0] / dataset.shape[0] * 100):.2f}%\\n\")\n",
        "\n",
        "# Class distribution in outliers\n",
        "for class_num in range(4):\n",
        "    class_count = (outliers_letters['label'] == class_num).sum()\n",
        "    class_percentage = (class_count / outliers_letters.shape[0] * 100)\n",
        "    class_names_dict = {0: 'Benign', 1: 'Defacement', 2: 'Phishing', 3: 'Malware'}\n",
        "\n",
        "    print(f\"Class {class_num} ({class_names_dict[class_num]}): {class_count:6d} samples | {class_percentage:5.2f}% of outliers\")\n",
        "\n",
        "# Compare with overall distribution\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARISON WITH OVERALL DATASET DISTRIBUTION\")\n",
        "print(\"=\"*60)\n",
        "for class_num in range(4):\n",
        "    overall_pct = (dataset_reduced['label'] == class_num).sum() / dataset_reduced.shape[0] * 100\n",
        "    outlier_pct = (outliers_url_len['label'] == class_num).sum() / outliers_url_len.shape[0] * 100\n",
        "    class_names_dict = {0: 'Benign', 1: 'Defacement', 2: 'Phishing', 3: 'Malware'}\n",
        "\n",
        "    print(f\"{class_names_dict[class_num]:12s}: Overall={overall_pct:5.2f}% | In url_len outliers={outlier_pct:5.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad95e04a",
      "metadata": {
        "id": "ad95e04a"
      },
      "outputs": [],
      "source": [
        "# remove outliers both on url_length and letter count.\n",
        "\n",
        "#url_len IQR bounds\n",
        "col = \"url_len\"\n",
        "Q1_url = dataset_reduced[col].quantile(0.25)\n",
        "Q3_url = dataset_reduced[col].quantile(0.75)\n",
        "IQR_url = Q3_url - Q1_url\n",
        "lower_url = Q1_url - 1.5 * IQR_url\n",
        "upper_url = Q3_url + 1.5 * IQR_url\n",
        "\n",
        "# letters IQR bounds\n",
        "col = \"letters\"\n",
        "Q1_let = dataset_reduced[col].quantile(0.25)\n",
        "Q3_let = dataset_reduced[col].quantile(0.75)\n",
        "IQR_let = Q3_let - Q1_let\n",
        "lower_let = Q1_let - 1.5 * IQR_let\n",
        "upper_let = Q3_let + 1.5 * IQR_let\n",
        "\n",
        "# Mask of non-outliers in both columns\n",
        "mask_url_ok = (dataset_reduced[\"url_len\"] >= lower_url) & (dataset_reduced[\"url_len\"] <= upper_url)\n",
        "mask_let_ok = (dataset_reduced[\"letters\"] >= lower_let) & (dataset_reduced[\"letters\"] <= upper_let)\n",
        "\n",
        "final_dataset = dataset_reduced[mask_url_ok & mask_let_ok].copy()\n",
        "\n",
        "print(\"Original reduced size:\", len(dataset_reduced))\n",
        "print(\"After removing outliers:\", len(final_dataset))\n",
        "print(\"Rows removed:\", len(dataset_reduced) - len(final_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "240a2ef7",
      "metadata": {
        "id": "240a2ef7"
      },
      "outputs": [],
      "source": [
        "# Show all columns in the DataFrame\n",
        "pd.set_option('display.max_columns', None)\n",
        "display(final_dataset.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5389d4c",
      "metadata": {
        "id": "b5389d4c"
      },
      "source": [
        "# Data Preproccessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1851ba9a",
      "metadata": {
        "id": "1851ba9a"
      },
      "outputs": [],
      "source": [
        "X = final_dataset.drop(columns=[\"label\"])\n",
        "y = final_dataset[\"label\"]\n",
        "\n",
        "# we use a randomstate = 3 for consistancy though the assignment\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ae5e3b7",
      "metadata": {
        "id": "9ae5e3b7"
      },
      "outputs": [],
      "source": [
        "# normalization / scaling\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "print(x_train_scaled.shape)\n",
        "print(x_test_scaled.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce8ea7f",
      "metadata": {
        "id": "0ce8ea7f"
      },
      "outputs": [],
      "source": [
        "print(x_train_scaled.mean(axis=0))\n",
        "print(\"\\n\")\n",
        "print(x_train_scaled.std(axis=0)) # Standard diviation for each feature"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76220989",
      "metadata": {
        "id": "76220989"
      },
      "source": [
        "# Evaluation of classification methods\n",
        "- in this section we compare three classifiers. Random Forest, Support Vector Machine and Naives Bayes.\n",
        "- We will collect all relevant measures from above classifiers. For each classfier we will train a final model and compare with each other.\n",
        "- to keep dual = false is important because we have more samples then features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc71a045",
      "metadata": {
        "id": "dc71a045"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=50, n_jobs=2, max_depth=30),\n",
        "    \"Linear SVM\": LinearSVC(random_state=42, dual=False, max_iter=10000),\n",
        "    \"Gaussian Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "f1_scores = {}\n",
        "confusion_predictions = {}  #predictions for confusion matrix\n",
        "confusion_matrices = {}\n",
        "training_times = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "412cc4b1",
      "metadata": {
        "id": "412cc4b1"
      },
      "outputs": [],
      "source": [
        "# here we perform all evaluations at the same time\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {name}...\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit(x_train_scaled, y_train)\n",
        "    y_pred = model.predict(x_test_scaled)\n",
        "    training_time = time.time() - start_time\n",
        "    training_times[name] = training_time\n",
        "\n",
        "    print(f\"✓ {name} trained in {training_time:.2f} seconds\")\n",
        "\n",
        "    confusion_predictions[name] = y_pred\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    confusion_matrices[name] = cm\n",
        "\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    f1_scores[name] = f1\n",
        "    print(f\"✓ F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00e8e97b",
      "metadata": {
        "id": "00e8e97b"
      },
      "source": [
        "# Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ddcd5e9",
      "metadata": {
        "id": "5ddcd5e9"
      },
      "outputs": [],
      "source": [
        "# Visualize F1 score\n",
        "\n",
        "f1_df = pd.DataFrame(f1_scores.items(), columns=['Algorithm', 'F1_Score'])\n",
        "f1_df['F1_Score (%)'] = f1_df['F1_Score'] * 100\n",
        "f1_df = f1_df.sort_values(by='F1_Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "sns.barplot(x='Algorithm', y='F1_Score (%)', data=f1_df, palette='magma')\n",
        "plt.title('Predictive Performance Comparison (F1-score)')\n",
        "plt.xlabel('Algorithm')\n",
        "plt.ylabel('F1-score (%)')\n",
        "plt.ylim(f1_df['F1_Score (%)'].min() - 1, 100)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30c4f6f9",
      "metadata": {
        "id": "30c4f6f9"
      },
      "outputs": [],
      "source": [
        "# Visualize confusion matrices\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "class_names = ['Benign', 'Defacement', 'Phishing', 'Malware']\n",
        "\n",
        "for idx, (name, cm) in enumerate(confusion_matrices.items()):\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    disp.plot(ax=axes[idx], cmap='Blues', values_format='d')\n",
        "    axes[idx].set_title(f'{name}\\nConfusion Matrix')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f226142",
      "metadata": {
        "id": "8f226142"
      },
      "outputs": [],
      "source": [
        "# Simplified per-class metrics display\n",
        "for name, cm in confusion_matrices.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{name}\")\n",
        "    print('='*60)\n",
        "\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        tp = cm[i, i]\n",
        "        fp = cm[:, i].sum() - tp\n",
        "        fn = cm[i, :].sum() - tp\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        print(f\"{class_name:12s}: Precision={precision*100:5.2f}% | Recall={recall*100:5.2f}% | F1={f1*100:5.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "352b89a4",
      "metadata": {
        "id": "352b89a4"
      },
      "source": [
        "# Train on total dataset using Random Forest\n",
        "    - we have evaluated all the classifiers using only 25% of the total dataset, we will now create the final model with Random Forest using the whole dataset. We will perform the same data cleaning steps as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc14e533",
      "metadata": {
        "id": "fc14e533"
      },
      "outputs": [],
      "source": [
        "# check z-score outliers\n",
        "\n",
        "# Check for outliers in url_len and letters\n",
        "col = 'url_len'\n",
        "Q1 = dataset[col].quantile(0.25)\n",
        "Q3 = dataset[col].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers_url_len = dataset[(dataset[col] < (Q1 - 1.5 * IQR)) | (dataset[col] > (Q3 + 1.5 * IQR))]\n",
        "print(f\"Outliers in '{col}': {outliers_url_len.shape[0]}\")\n",
        "\n",
        "col = 'letters'\n",
        "Q1 = dataset[col].quantile(0.25)\n",
        "Q3 = dataset[col].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers_letters = dataset[(dataset[col] < (Q1 - 1.5 * IQR)) | (dataset[col] > (Q3 + 1.5 * IQR))]\n",
        "print(f\"Outliers in '{col}': {outliers_letters.shape[0]}\")\n",
        "\n",
        "\n",
        "# remove outliers both on url_length and letter count.\n",
        "\n",
        "#url_len IQR bounds\n",
        "col = \"url_len\"\n",
        "Q1_url = dataset[col].quantile(0.25)\n",
        "Q3_url = dataset[col].quantile(0.75)\n",
        "IQR_url = Q3_url - Q1_url\n",
        "lower_url = Q1_url - 1.5 * IQR_url\n",
        "upper_url = Q3_url + 1.5 * IQR_url\n",
        "\n",
        "# letters IQR bounds\n",
        "col = \"letters\"\n",
        "Q1_let = dataset[col].quantile(0.25)\n",
        "Q3_let = dataset[col].quantile(0.75)\n",
        "IQR_let = Q3_let - Q1_let\n",
        "lower_let = Q1_let - 1.5 * IQR_let\n",
        "upper_let = Q3_let + 1.5 * IQR_let\n",
        "\n",
        "# Mask of non-outliers in both columns\n",
        "mask_url_ok = (dataset[\"url_len\"] >= lower_url) & (dataset[\"url_len\"] <= upper_url)\n",
        "mask_let_ok = (dataset[\"letters\"] >= lower_let) & (dataset[\"letters\"] <= upper_let)\n",
        "\n",
        "total_cleaned_dataset = dataset[mask_url_ok & mask_let_ok].copy()\n",
        "\n",
        "print(\"Original reduced size:\", len(dataset))\n",
        "print(\"After removing outliers:\", len(total_cleaned_dataset))\n",
        "print(\"Rows removed:\", len(dataset) - len(total_cleaned_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b58bad77",
      "metadata": {
        "id": "b58bad77"
      },
      "outputs": [],
      "source": [
        "X = total_cleaned_dataset.drop(columns=[\"label\"])\n",
        "y = total_cleaned_dataset[\"label\"]\n",
        "\n",
        "# we use a randomstate = 3 for consistancy though the assignment\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d861227",
      "metadata": {
        "id": "2d861227"
      },
      "outputs": [],
      "source": [
        "# normalization / scaling\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5722d94",
      "metadata": {
        "id": "a5722d94"
      },
      "outputs": [],
      "source": [
        "# training final model\n",
        "\n",
        "rfc = RandomForestClassifier(random_state=42, n_estimators=50, n_jobs=2, max_depth=30)\n",
        "\n",
        "rfc.fit(x_train_scaled, y_train)\n",
        "y_pred = rfc.predict(x_test_scaled)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "print(f\"Final models F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c23e017",
      "metadata": {
        "id": "8c23e017"
      },
      "outputs": [],
      "source": [
        "cm_final = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL MODEL - Per-Class Performance\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "class_names = ['Benign', 'Defacement', 'Phishing', 'Malware']\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    tp = cm_final[i, i]\n",
        "    fp = cm_final[:, i].sum() - tp\n",
        "    fn = cm_final[i, :].sum() - tp\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_class = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    print(f\"{class_name:12s}: Precision={precision*100:5.2f}% | Recall={recall*100:5.2f}% | F1={f1_class*100:5.2f}%\")\n",
        "\n",
        "# Visualize confusion matrix for final model\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Confusion Matrix Visualization\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_final, display_labels=class_names)\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Random Forest - Final Model\\nConfusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ade3db3e",
      "metadata": {
        "id": "ade3db3e"
      },
      "source": [
        "Refrences\n",
        "https://www.kaggle.com/datasets/moutasmtamimi/malicious-url-detection-dataset-enhanced-2026\n",
        "https://www.kaggle.com/datasets/nhutrinhanna/malicious-and-benign-urls-datasets"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}